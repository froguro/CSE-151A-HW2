{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ceeeb46",
   "metadata": {
    "id": "0ceeeb46"
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "For this assignment, you will be developing an artificial neural network to classify data given in the __[Dry Beans Data Set](https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset#)__. This data set was obtained as a part of a research study by Selcuk University, Turkey, in which a computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features. More details on the study can be found in the following __[research paper](https://www.sciencedirect.com/science/article/pii/S0168169919311573)__. <br>\n",
    "### **Make sure to use the lecture notebook on an introduction to keras and cross validation located [here](https://colab.research.google.com/drive/1ksEGL7SJ_wutCIyPYx7Loe5EPdOij6dJ?usp=sharing) and [here](https://colab.research.google.com/drive/1C9Mwf1J2ril1Q4l6n2BjQMb8YaFySG5_?usp=sharing)**.\n",
    "\n",
    "## About the Data Set\n",
    "Seven different types of dry beans were used in a study in Selcuk University, Turkey, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the **classification** model, images of 13611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features - 12 dimensions and 4 shape forms - were obtained from the grains.\n",
    "\n",
    "Number of Instances (records in the data set): __13611__\n",
    "\n",
    "Number of Attributes (fields within each record, including the class): __17__\n",
    "\n",
    "### Data Set Attribute Information:\n",
    "\n",
    "1. __Area (A)__ : The area of a bean zone and the number of pixels within its boundaries.\n",
    "2. __Perimeter (P)__ : Bean circumference is defined as the length of its border.\n",
    "3. __Major axis length (L)__ : The distance between the ends of the longest line that can be drawn from a bean.\n",
    "4. __Minor axis length (l)__ : The longest line that can be drawn from the bean while standing perpendicular to the main axis.\n",
    "5. __Aspect ratio (K)__ : Defines the relationship between L and l.\n",
    "6. __Eccentricity (Ec)__ : Eccentricity of the ellipse having the same moments as the region.\n",
    "7. __Convex area (C)__ : Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\n",
    "8. __Equivalent diameter (Ed)__ : The diameter of a circle having the same area as a bean seed area.\n",
    "9. __Extent (Ex)__ : The ratio of the pixels in the bounding box to the bean area.\n",
    "10. __Solidity (S)__ : Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\n",
    "11. __Roundness (R)__ : Calculated with the following formula: (4piA)/(P^2)\n",
    "12. __Compactness (CO)__ : Measures the roundness of an object: Ed/L\n",
    "13. __ShapeFactor1 (SF1)__\n",
    "14. __ShapeFactor2 (SF2)__\n",
    "15. __ShapeFactor3 (SF3)__\n",
    "16. __ShapeFactor4 (SF4)__\n",
    "\n",
    "17. __Classes : *Seker, Barbunya, Bombay, Cali, Dermosan, Horoz, Sira*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61beac74",
   "metadata": {
    "id": "61beac74"
   },
   "source": [
    "### Libraries that can be used :\n",
    "- NumPy, SciPy, Pandas, Sci-Kit Learn, TensorFlow, Keras. You may also use PyTorch (though support may be limited)\n",
    "- Any other library used during the lectures and discussion sessions.\n",
    "\n",
    "### Other Notes\n",
    "- Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of this assignment.\n",
    "- Discussion and Lecture materials should be helpful for doing the assignments.\n",
    "- The homework submission should be a .ipynb file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LcVrrFbn1wzE",
   "metadata": {
    "id": "LcVrrFbn1wzE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'hw2'...\n",
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 25 (delta 11), reused 3 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (25/25), 1.56 MiB | 4.08 MiB/s, done.\n",
      "Resolving deltas: 100% (11/11), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ucsd-cse151a-ss124/hw2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e29b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c751",
   "metadata": {
    "id": "0264c751"
   },
   "source": [
    "\n",
    "## Exercise 1 : Building a Feed-Forward Neural Network(50 points)\n",
    "\n",
    "### Exercise 1.1 : Data Preprocessing (10 points)\n",
    "\n",
    "- As the classes are categorical, use one-hot encoding to represent the set of classes. You will find this useful when developing the output layer of the neural network.\n",
    "- Normalize each field of the input data using the min-max normalization technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1St-29dI04l3",
   "metadata": {
    "id": "1St-29dI04l3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44830</td>\n",
       "      <td>814.955</td>\n",
       "      <td>320.731947</td>\n",
       "      <td>178.405838</td>\n",
       "      <td>1.797766</td>\n",
       "      <td>0.831018</td>\n",
       "      <td>45297</td>\n",
       "      <td>238.912806</td>\n",
       "      <td>0.658877</td>\n",
       "      <td>0.989690</td>\n",
       "      <td>0.848226</td>\n",
       "      <td>0.744899</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.554874</td>\n",
       "      <td>0.997534</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33476</td>\n",
       "      <td>691.826</td>\n",
       "      <td>258.837971</td>\n",
       "      <td>165.220760</td>\n",
       "      <td>1.566619</td>\n",
       "      <td>0.769773</td>\n",
       "      <td>33907</td>\n",
       "      <td>206.453305</td>\n",
       "      <td>0.721155</td>\n",
       "      <td>0.987289</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.797616</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27057</td>\n",
       "      <td>606.138</td>\n",
       "      <td>227.460904</td>\n",
       "      <td>151.860320</td>\n",
       "      <td>1.497830</td>\n",
       "      <td>0.744491</td>\n",
       "      <td>27358</td>\n",
       "      <td>185.607226</td>\n",
       "      <td>0.801831</td>\n",
       "      <td>0.988998</td>\n",
       "      <td>0.925436</td>\n",
       "      <td>0.815996</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.665850</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49483</td>\n",
       "      <td>844.283</td>\n",
       "      <td>326.602913</td>\n",
       "      <td>194.689529</td>\n",
       "      <td>1.677558</td>\n",
       "      <td>0.802907</td>\n",
       "      <td>50289</td>\n",
       "      <td>251.005403</td>\n",
       "      <td>0.680179</td>\n",
       "      <td>0.983973</td>\n",
       "      <td>0.872348</td>\n",
       "      <td>0.768534</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.590644</td>\n",
       "      <td>0.990840</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22461</td>\n",
       "      <td>544.584</td>\n",
       "      <td>192.801303</td>\n",
       "      <td>148.541136</td>\n",
       "      <td>1.297966</td>\n",
       "      <td>0.637517</td>\n",
       "      <td>22699</td>\n",
       "      <td>169.110122</td>\n",
       "      <td>0.774731</td>\n",
       "      <td>0.989515</td>\n",
       "      <td>0.951720</td>\n",
       "      <td>0.877121</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.769342</td>\n",
       "      <td>0.998579</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>39956</td>\n",
       "      <td>745.166</td>\n",
       "      <td>273.867402</td>\n",
       "      <td>186.564001</td>\n",
       "      <td>1.467954</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>40504</td>\n",
       "      <td>225.551678</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.986470</td>\n",
       "      <td>0.904244</td>\n",
       "      <td>0.823580</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.678284</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>171914</td>\n",
       "      <td>1595.676</td>\n",
       "      <td>598.541646</td>\n",
       "      <td>368.358372</td>\n",
       "      <td>1.624889</td>\n",
       "      <td>0.788194</td>\n",
       "      <td>174673</td>\n",
       "      <td>467.854361</td>\n",
       "      <td>0.815980</td>\n",
       "      <td>0.984205</td>\n",
       "      <td>0.848461</td>\n",
       "      <td>0.781657</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.610988</td>\n",
       "      <td>0.992788</td>\n",
       "      <td>BOMBAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>48266</td>\n",
       "      <td>817.340</td>\n",
       "      <td>304.682706</td>\n",
       "      <td>202.282198</td>\n",
       "      <td>1.506226</td>\n",
       "      <td>0.747812</td>\n",
       "      <td>48780</td>\n",
       "      <td>247.899536</td>\n",
       "      <td>0.807232</td>\n",
       "      <td>0.989463</td>\n",
       "      <td>0.907916</td>\n",
       "      <td>0.813632</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.661997</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>43279</td>\n",
       "      <td>843.066</td>\n",
       "      <td>336.280446</td>\n",
       "      <td>164.667135</td>\n",
       "      <td>2.042183</td>\n",
       "      <td>0.871907</td>\n",
       "      <td>43813</td>\n",
       "      <td>234.743550</td>\n",
       "      <td>0.614566</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.765181</td>\n",
       "      <td>0.698059</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.487286</td>\n",
       "      <td>0.995128</td>\n",
       "      <td>HOROZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>46856</td>\n",
       "      <td>809.173</td>\n",
       "      <td>302.595376</td>\n",
       "      <td>197.920303</td>\n",
       "      <td>1.528875</td>\n",
       "      <td>0.756429</td>\n",
       "      <td>47372</td>\n",
       "      <td>244.251739</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.989107</td>\n",
       "      <td>0.899275</td>\n",
       "      <td>0.807189</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.651555</td>\n",
       "      <td>0.996145</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0       44830    814.955       320.731947       178.405838      1.797766   \n",
       "1       33476    691.826       258.837971       165.220760      1.566619   \n",
       "2       27057    606.138       227.460904       151.860320      1.497830   \n",
       "3       49483    844.283       326.602913       194.689529      1.677558   \n",
       "4       22461    544.584       192.801303       148.541136      1.297966   \n",
       "...       ...        ...              ...              ...           ...   \n",
       "13606   39956    745.166       273.867402       186.564001      1.467954   \n",
       "13607  171914   1595.676       598.541646       368.358372      1.624889   \n",
       "13608   48266    817.340       304.682706       202.282198      1.506226   \n",
       "13609   43279    843.066       336.280446       164.667135      2.042183   \n",
       "13610   46856    809.173       302.595376       197.920303      1.528875   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.831018       45297     238.912806  0.658877  0.989690   0.848226   \n",
       "1          0.769773       33907     206.453305  0.721155  0.987289   0.878921   \n",
       "2          0.744491       27358     185.607226  0.801831  0.988998   0.925436   \n",
       "3          0.802907       50289     251.005403  0.680179  0.983973   0.872348   \n",
       "4          0.637517       22699     169.110122  0.774731  0.989515   0.951720   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.732079       40504     225.551678  0.796000  0.986470   0.904244   \n",
       "13607      0.788194      174673     467.854361  0.815980  0.984205   0.848461   \n",
       "13608      0.747812       48780     247.899536  0.807232  0.989463   0.907916   \n",
       "13609      0.871907       43813     234.743550  0.614566  0.987812   0.765181   \n",
       "13610      0.756429       47372     244.251739  0.726900  0.989107   0.899275   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0         0.744899      0.007154      0.001359      0.554874      0.997534   \n",
       "1         0.797616      0.007732      0.001930      0.636191      0.996669   \n",
       "2         0.815996      0.008407      0.002299      0.665850      0.997330   \n",
       "3         0.768534      0.006600      0.001420      0.590644      0.990840   \n",
       "4         0.877121      0.008584      0.003134      0.769342      0.998579   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13606     0.823580      0.006854      0.001945      0.678284      0.995690   \n",
       "13607     0.781657      0.003482      0.000802      0.610988      0.992788   \n",
       "13608     0.813632      0.006313      0.001706      0.661997      0.997117   \n",
       "13609     0.698059      0.007770      0.001138      0.487286      0.995128   \n",
       "13610     0.807189      0.006458      0.001691      0.651555      0.996145   \n",
       "\n",
       "          Class  \n",
       "0          SIRA  \n",
       "1      DERMASON  \n",
       "2      DERMASON  \n",
       "3          SIRA  \n",
       "4      DERMASON  \n",
       "...         ...  \n",
       "13606  DERMASON  \n",
       "13607    BOMBAY  \n",
       "13608      SIRA  \n",
       "13609     HOROZ  \n",
       "13610      SIRA  \n",
       "\n",
       "[13611 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drybeans_df = pd.read_csv('Dry_Beans_Dataset.csv')\n",
    "drybeans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8051b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>...</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class_BARBUNYA</th>\n",
       "      <th>Class_BOMBAY</th>\n",
       "      <th>Class_CALI</th>\n",
       "      <th>Class_DERMASON</th>\n",
       "      <th>Class_HOROZ</th>\n",
       "      <th>Class_SEKER</th>\n",
       "      <th>Class_SIRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44830</td>\n",
       "      <td>814.955</td>\n",
       "      <td>320.731947</td>\n",
       "      <td>178.405838</td>\n",
       "      <td>1.797766</td>\n",
       "      <td>0.831018</td>\n",
       "      <td>45297</td>\n",
       "      <td>238.912806</td>\n",
       "      <td>0.658877</td>\n",
       "      <td>0.989690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.554874</td>\n",
       "      <td>0.997534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33476</td>\n",
       "      <td>691.826</td>\n",
       "      <td>258.837971</td>\n",
       "      <td>165.220760</td>\n",
       "      <td>1.566619</td>\n",
       "      <td>0.769773</td>\n",
       "      <td>33907</td>\n",
       "      <td>206.453305</td>\n",
       "      <td>0.721155</td>\n",
       "      <td>0.987289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27057</td>\n",
       "      <td>606.138</td>\n",
       "      <td>227.460904</td>\n",
       "      <td>151.860320</td>\n",
       "      <td>1.497830</td>\n",
       "      <td>0.744491</td>\n",
       "      <td>27358</td>\n",
       "      <td>185.607226</td>\n",
       "      <td>0.801831</td>\n",
       "      <td>0.988998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.665850</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49483</td>\n",
       "      <td>844.283</td>\n",
       "      <td>326.602913</td>\n",
       "      <td>194.689529</td>\n",
       "      <td>1.677558</td>\n",
       "      <td>0.802907</td>\n",
       "      <td>50289</td>\n",
       "      <td>251.005403</td>\n",
       "      <td>0.680179</td>\n",
       "      <td>0.983973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.590644</td>\n",
       "      <td>0.990840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22461</td>\n",
       "      <td>544.584</td>\n",
       "      <td>192.801303</td>\n",
       "      <td>148.541136</td>\n",
       "      <td>1.297966</td>\n",
       "      <td>0.637517</td>\n",
       "      <td>22699</td>\n",
       "      <td>169.110122</td>\n",
       "      <td>0.774731</td>\n",
       "      <td>0.989515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.769342</td>\n",
       "      <td>0.998579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>39956</td>\n",
       "      <td>745.166</td>\n",
       "      <td>273.867402</td>\n",
       "      <td>186.564001</td>\n",
       "      <td>1.467954</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>40504</td>\n",
       "      <td>225.551678</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.986470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.678284</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>171914</td>\n",
       "      <td>1595.676</td>\n",
       "      <td>598.541646</td>\n",
       "      <td>368.358372</td>\n",
       "      <td>1.624889</td>\n",
       "      <td>0.788194</td>\n",
       "      <td>174673</td>\n",
       "      <td>467.854361</td>\n",
       "      <td>0.815980</td>\n",
       "      <td>0.984205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.610988</td>\n",
       "      <td>0.992788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>48266</td>\n",
       "      <td>817.340</td>\n",
       "      <td>304.682706</td>\n",
       "      <td>202.282198</td>\n",
       "      <td>1.506226</td>\n",
       "      <td>0.747812</td>\n",
       "      <td>48780</td>\n",
       "      <td>247.899536</td>\n",
       "      <td>0.807232</td>\n",
       "      <td>0.989463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.661997</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>43279</td>\n",
       "      <td>843.066</td>\n",
       "      <td>336.280446</td>\n",
       "      <td>164.667135</td>\n",
       "      <td>2.042183</td>\n",
       "      <td>0.871907</td>\n",
       "      <td>43813</td>\n",
       "      <td>234.743550</td>\n",
       "      <td>0.614566</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.487286</td>\n",
       "      <td>0.995128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>46856</td>\n",
       "      <td>809.173</td>\n",
       "      <td>302.595376</td>\n",
       "      <td>197.920303</td>\n",
       "      <td>1.528875</td>\n",
       "      <td>0.756429</td>\n",
       "      <td>47372</td>\n",
       "      <td>244.251739</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.989107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.651555</td>\n",
       "      <td>0.996145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0       44830    814.955       320.731947       178.405838      1.797766   \n",
       "1       33476    691.826       258.837971       165.220760      1.566619   \n",
       "2       27057    606.138       227.460904       151.860320      1.497830   \n",
       "3       49483    844.283       326.602913       194.689529      1.677558   \n",
       "4       22461    544.584       192.801303       148.541136      1.297966   \n",
       "...       ...        ...              ...              ...           ...   \n",
       "13606   39956    745.166       273.867402       186.564001      1.467954   \n",
       "13607  171914   1595.676       598.541646       368.358372      1.624889   \n",
       "13608   48266    817.340       304.682706       202.282198      1.506226   \n",
       "13609   43279    843.066       336.280446       164.667135      2.042183   \n",
       "13610   46856    809.173       302.595376       197.920303      1.528875   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  ...  \\\n",
       "0          0.831018       45297     238.912806  0.658877  0.989690  ...   \n",
       "1          0.769773       33907     206.453305  0.721155  0.987289  ...   \n",
       "2          0.744491       27358     185.607226  0.801831  0.988998  ...   \n",
       "3          0.802907       50289     251.005403  0.680179  0.983973  ...   \n",
       "4          0.637517       22699     169.110122  0.774731  0.989515  ...   \n",
       "...             ...         ...            ...       ...       ...  ...   \n",
       "13606      0.732079       40504     225.551678  0.796000  0.986470  ...   \n",
       "13607      0.788194      174673     467.854361  0.815980  0.984205  ...   \n",
       "13608      0.747812       48780     247.899536  0.807232  0.989463  ...   \n",
       "13609      0.871907       43813     234.743550  0.614566  0.987812  ...   \n",
       "13610      0.756429       47372     244.251739  0.726900  0.989107  ...   \n",
       "\n",
       "       ShapeFactor2  ShapeFactor3  ShapeFactor4  Class_BARBUNYA  Class_BOMBAY  \\\n",
       "0          0.001359      0.554874      0.997534             0.0           0.0   \n",
       "1          0.001930      0.636191      0.996669             0.0           0.0   \n",
       "2          0.002299      0.665850      0.997330             0.0           0.0   \n",
       "3          0.001420      0.590644      0.990840             0.0           0.0   \n",
       "4          0.003134      0.769342      0.998579             0.0           0.0   \n",
       "...             ...           ...           ...             ...           ...   \n",
       "13606      0.001945      0.678284      0.995690             0.0           0.0   \n",
       "13607      0.000802      0.610988      0.992788             0.0           1.0   \n",
       "13608      0.001706      0.661997      0.997117             0.0           0.0   \n",
       "13609      0.001138      0.487286      0.995128             0.0           0.0   \n",
       "13610      0.001691      0.651555      0.996145             0.0           0.0   \n",
       "\n",
       "       Class_CALI  Class_DERMASON  Class_HOROZ  Class_SEKER  Class_SIRA  \n",
       "0             0.0             0.0          0.0          0.0         1.0  \n",
       "1             0.0             1.0          0.0          0.0         0.0  \n",
       "2             0.0             1.0          0.0          0.0         0.0  \n",
       "3             0.0             0.0          0.0          0.0         1.0  \n",
       "4             0.0             1.0          0.0          0.0         0.0  \n",
       "...           ...             ...          ...          ...         ...  \n",
       "13606         0.0             1.0          0.0          0.0         0.0  \n",
       "13607         0.0             0.0          0.0          0.0         0.0  \n",
       "13608         0.0             0.0          0.0          0.0         1.0  \n",
       "13609         0.0             0.0          1.0          0.0         0.0  \n",
       "13610         0.0             0.0          0.0          0.0         1.0  \n",
       "\n",
       "[13611 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drybeans_df = pd.get_dummies(drybeans_df, prefix=['Class'], columns=['Class'], dtype=float)\n",
    "drybeans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9436cd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>...</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class_BARBUNYA</th>\n",
       "      <th>Class_BOMBAY</th>\n",
       "      <th>Class_CALI</th>\n",
       "      <th>Class_DERMASON</th>\n",
       "      <th>Class_HOROZ</th>\n",
       "      <th>Class_SEKER</th>\n",
       "      <th>Class_SIRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104229</td>\n",
       "      <td>0.198694</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>0.165518</td>\n",
       "      <td>0.549934</td>\n",
       "      <td>0.883887</td>\n",
       "      <td>0.101465</td>\n",
       "      <td>0.190304</td>\n",
       "      <td>0.333127</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256253</td>\n",
       "      <td>0.256074</td>\n",
       "      <td>0.957751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055748</td>\n",
       "      <td>0.114396</td>\n",
       "      <td>0.135499</td>\n",
       "      <td>0.126473</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.110772</td>\n",
       "      <td>0.533453</td>\n",
       "      <td>0.902047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440609</td>\n",
       "      <td>0.400144</td>\n",
       "      <td>0.941143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028340</td>\n",
       "      <td>0.055731</td>\n",
       "      <td>0.078990</td>\n",
       "      <td>0.086908</td>\n",
       "      <td>0.336523</td>\n",
       "      <td>0.758933</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.059695</td>\n",
       "      <td>0.792964</td>\n",
       "      <td>0.924703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559513</td>\n",
       "      <td>0.452690</td>\n",
       "      <td>0.953829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124097</td>\n",
       "      <td>0.218773</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.464403</td>\n",
       "      <td>0.843291</td>\n",
       "      <td>0.122044</td>\n",
       "      <td>0.219934</td>\n",
       "      <td>0.401647</td>\n",
       "      <td>0.858085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276116</td>\n",
       "      <td>0.319448</td>\n",
       "      <td>0.829136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.013589</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>0.077079</td>\n",
       "      <td>0.194315</td>\n",
       "      <td>0.604452</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.705791</td>\n",
       "      <td>0.931560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828764</td>\n",
       "      <td>0.636047</td>\n",
       "      <td>0.977839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>0.083417</td>\n",
       "      <td>0.150914</td>\n",
       "      <td>0.162566</td>\n",
       "      <td>0.189677</td>\n",
       "      <td>0.315266</td>\n",
       "      <td>0.741008</td>\n",
       "      <td>0.081706</td>\n",
       "      <td>0.157567</td>\n",
       "      <td>0.774206</td>\n",
       "      <td>0.891199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445374</td>\n",
       "      <td>0.474719</td>\n",
       "      <td>0.922317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>0.646868</td>\n",
       "      <td>0.733202</td>\n",
       "      <td>0.747292</td>\n",
       "      <td>0.728031</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>0.822045</td>\n",
       "      <td>0.634805</td>\n",
       "      <td>0.751256</td>\n",
       "      <td>0.838477</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076613</td>\n",
       "      <td>0.355491</td>\n",
       "      <td>0.866564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.200327</td>\n",
       "      <td>0.218063</td>\n",
       "      <td>0.236224</td>\n",
       "      <td>0.342497</td>\n",
       "      <td>0.763728</td>\n",
       "      <td>0.115823</td>\n",
       "      <td>0.212324</td>\n",
       "      <td>0.810335</td>\n",
       "      <td>0.930870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368388</td>\n",
       "      <td>0.445864</td>\n",
       "      <td>0.949738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>0.097606</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.124833</td>\n",
       "      <td>0.723842</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>0.095347</td>\n",
       "      <td>0.180089</td>\n",
       "      <td>0.190594</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185084</td>\n",
       "      <td>0.136328</td>\n",
       "      <td>0.911521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>0.112880</td>\n",
       "      <td>0.194735</td>\n",
       "      <td>0.214304</td>\n",
       "      <td>0.223307</td>\n",
       "      <td>0.358612</td>\n",
       "      <td>0.776173</td>\n",
       "      <td>0.110019</td>\n",
       "      <td>0.203386</td>\n",
       "      <td>0.551936</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363443</td>\n",
       "      <td>0.427363</td>\n",
       "      <td>0.931075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0      0.104229   0.198694         0.246967         0.165518      0.549934   \n",
       "1      0.055748   0.114396         0.135499         0.126473      0.385468   \n",
       "2      0.028340   0.055731         0.078990         0.086908      0.336523   \n",
       "3      0.124097   0.218773         0.257541         0.213740      0.464403   \n",
       "4      0.008715   0.013589         0.016569         0.077079      0.194315   \n",
       "...         ...        ...              ...              ...           ...   \n",
       "13606  0.083417   0.150914         0.162566         0.189677      0.315266   \n",
       "13607  0.646868   0.733202         0.747292         0.728031      0.426928   \n",
       "13608  0.118900   0.200327         0.218063         0.236224      0.342497   \n",
       "13609  0.097606   0.217940         0.274969         0.124833      0.723842   \n",
       "13610  0.112880   0.194735         0.214304         0.223307      0.358612   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  ...  \\\n",
       "0          0.883887    0.101465       0.190304  0.333127  0.933884  ...   \n",
       "1          0.795443    0.054511       0.110772  0.533453  0.902047  ...   \n",
       "2          0.758933    0.027513       0.059695  0.792964  0.924703  ...   \n",
       "3          0.843291    0.122044       0.219934  0.401647  0.858085  ...   \n",
       "4          0.604452    0.008307       0.019274  0.705791  0.931560  ...   \n",
       "...             ...         ...            ...       ...       ...  ...   \n",
       "13606      0.741008    0.081706       0.157567  0.774206  0.891199  ...   \n",
       "13607      0.822045    0.634805       0.751256  0.838477  0.861162  ...   \n",
       "13608      0.763728    0.115823       0.212324  0.810335  0.930870  ...   \n",
       "13609      0.942934    0.095347       0.180089  0.190594  0.908981  ...   \n",
       "13610      0.776173    0.110019       0.203386  0.551936  0.926158  ...   \n",
       "\n",
       "       ShapeFactor2  ShapeFactor3  ShapeFactor4  Class_BARBUNYA  Class_BOMBAY  \\\n",
       "0          0.256253      0.256074      0.957751             0.0           0.0   \n",
       "1          0.440609      0.400144      0.941143             0.0           0.0   \n",
       "2          0.559513      0.452690      0.953829             0.0           0.0   \n",
       "3          0.276116      0.319448      0.829136             0.0           0.0   \n",
       "4          0.828764      0.636047      0.977839             0.0           0.0   \n",
       "...             ...           ...           ...             ...           ...   \n",
       "13606      0.445374      0.474719      0.922317             0.0           0.0   \n",
       "13607      0.076613      0.355491      0.866564             0.0           1.0   \n",
       "13608      0.368388      0.445864      0.949738             0.0           0.0   \n",
       "13609      0.185084      0.136328      0.911521             0.0           0.0   \n",
       "13610      0.363443      0.427363      0.931075             0.0           0.0   \n",
       "\n",
       "       Class_CALI  Class_DERMASON  Class_HOROZ  Class_SEKER  Class_SIRA  \n",
       "0             0.0             0.0          0.0          0.0         1.0  \n",
       "1             0.0             1.0          0.0          0.0         0.0  \n",
       "2             0.0             1.0          0.0          0.0         0.0  \n",
       "3             0.0             0.0          0.0          0.0         1.0  \n",
       "4             0.0             1.0          0.0          0.0         0.0  \n",
       "...           ...             ...          ...          ...         ...  \n",
       "13606         0.0             1.0          0.0          0.0         0.0  \n",
       "13607         0.0             0.0          0.0          0.0         0.0  \n",
       "13608         0.0             0.0          0.0          0.0         1.0  \n",
       "13609         0.0             0.0          1.0          0.0         0.0  \n",
       "13610         0.0             0.0          0.0          0.0         1.0  \n",
       "\n",
       "[13611 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax Normalization\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "drybeans_df = pd.DataFrame(scaler.fit_transform(drybeans_df), columns = drybeans_df.columns)\n",
    "drybeans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o4QPlcYa0sHN",
   "metadata": {
    "id": "o4QPlcYa0sHN"
   },
   "source": [
    "### Exercise 1.2 : Training and Testing the Neural Network (40 points)\n",
    "\n",
    "Design a 4-layer (4 hidden layers and this does not include the input or output layer) artificial deep neural network, specifically a feed-forward multi-layer perceptron (using the sigmoid activation function), to classify the type of 'Dry Bean' given the other attributes in the data set, similar to the one mentioned in the paper above. Please note that this is a **multi-class classification** problem so select the right number of nodes accordingly for the input and output layers.\n",
    "\n",
    "For training and testing the model, split the data into training and testing set by __90:10__ and use the training set for training the model and the test set to evaluate the model performance.\n",
    "\n",
    "Consider the following hyperparameters while developing your model :\n",
    "\n",
    "- Model type: Keras Sequential\n",
    "- Make sure your input layer matches the size of your X matrix\n",
    "- Number and type of hidden layers: 4 and Dense\n",
    "- Number of nodes in each hidden layer: 12\n",
    "- Learning rate should be 0.3\n",
    "- Number of epochs should be 100\n",
    "- The sigmoid function is to be used as the activation function in each layer\n",
    "- Your output layer has to use a sigmoid function and the number of outputs should match the shape of your y\n",
    "- Stochastic Gradient Descent should be used to minimize the error rate\n",
    "\n",
    "__Requirements once the model has been trained :__\n",
    "\n",
    "- A confusion matrix for all classes, specifying the true positive, true negative, false positive, and false negative cases for each category in the class\n",
    "- Since we do have OHE output (multi-class output) you will need to either reshape or argmax your outputs. Make sure they have already been thresholded as well i.e. look at yhat and do you see 1's and 0's?\n",
    "- The accuracy and mean squared error (MSE) of the model\n",
    "- The precision and recall for each label in the class\n",
    "\n",
    "__Notes :__\n",
    "\n",
    "- Splitting of the dataset should be done __after__ the data preprocessing step.\n",
    "- The mean squared error (MSE) values obtained __should be positive__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650651a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "KhW7lew706U8",
   "metadata": {
    "id": "KhW7lew706U8"
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(drybeans_df.iloc[:,:16], drybeans_df.iloc[:,16:], test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd27d08-4858-413f-9c7b-e8717ad5a91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12249, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50a0b00-4df6-4097-920f-5da646a0eee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12249, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb31fa5e-b3a2-49d3-ad24-bd5f2df3b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Input(shape=(16,)))\n",
    "classifier.add(Dense(units=12,activation='sigmoid'))\n",
    "classifier.add(Dense(units=12,activation='sigmoid'))\n",
    "classifier.add(Dense(units=12,activation='sigmoid'))\n",
    "classifier.add(Dense(units=12,activation='sigmoid'))\n",
    "classifier.add(Dense(units=7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8878bd86-2d86-4ac0-9c40-f03faddf4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=SGD(learning_rate=0.3), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8cc7de-7673-49f5-bd1a-44c8bcaa851b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m156\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m156\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m156\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m91\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">763</span> (2.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m763\u001b[0m (2.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">763</span> (2.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m763\u001b[0m (2.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6167b27-b07e-43f9-8d7a-6f13a2eef302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 7), dtype=float32, sparse=False, name=keras_tensor_15>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb624d7-ed18-49d4-aa56-ffe30498f99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:27:01.722535: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.2355 - loss: 1.8667\n",
      "Epoch 2/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.2502 - loss: 1.8431\n",
      "Epoch 3/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.2563 - loss: 1.8447\n",
      "Epoch 4/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.2538 - loss: 1.8361\n",
      "Epoch 5/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.2522 - loss: 1.8319\n",
      "Epoch 6/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.4821 - loss: 1.2126\n",
      "Epoch 7/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.5487 - loss: 0.9981\n",
      "Epoch 8/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.6089 - loss: 0.9127\n",
      "Epoch 9/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.6722 - loss: 0.8114\n",
      "Epoch 10/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7268 - loss: 0.7334\n",
      "Epoch 11/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.7688 - loss: 0.6328\n",
      "Epoch 12/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.8105 - loss: 0.5341\n",
      "Epoch 13/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8639 - loss: 0.3842\n",
      "Epoch 14/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8700 - loss: 0.3590\n",
      "Epoch 15/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.8791 - loss: 0.3302\n",
      "Epoch 16/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.8869 - loss: 0.3235\n",
      "Epoch 17/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.8938 - loss: 0.2969\n",
      "Epoch 18/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.8956 - loss: 0.2895\n",
      "Epoch 19/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.9046 - loss: 0.2766\n",
      "Epoch 20/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.9045 - loss: 0.2765\n",
      "Epoch 21/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.9014 - loss: 0.2857\n",
      "Epoch 22/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.9025 - loss: 0.2760\n",
      "Epoch 23/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - accuracy: 0.9030 - loss: 0.2682\n",
      "Epoch 24/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.9022 - loss: 0.2752\n",
      "Epoch 25/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.9037 - loss: 0.2730\n",
      "Epoch 26/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.9089 - loss: 0.2586\n",
      "Epoch 27/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.9089 - loss: 0.2603\n",
      "Epoch 28/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485us/step - accuracy: 0.9048 - loss: 0.2600\n",
      "Epoch 29/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.9060 - loss: 0.2602\n",
      "Epoch 30/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.9066 - loss: 0.2585\n",
      "Epoch 31/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - accuracy: 0.9086 - loss: 0.2577\n",
      "Epoch 32/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.9051 - loss: 0.2590\n",
      "Epoch 33/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.9132 - loss: 0.2513\n",
      "Epoch 34/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.9173 - loss: 0.2345\n",
      "Epoch 35/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.9069 - loss: 0.2569\n",
      "Epoch 36/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9147 - loss: 0.2430\n",
      "Epoch 37/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.9140 - loss: 0.2436\n",
      "Epoch 38/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482us/step - accuracy: 0.9046 - loss: 0.2556\n",
      "Epoch 39/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step - accuracy: 0.9134 - loss: 0.2367\n",
      "Epoch 40/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - accuracy: 0.9103 - loss: 0.2490\n",
      "Epoch 41/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.9116 - loss: 0.2488\n",
      "Epoch 42/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - accuracy: 0.9124 - loss: 0.2352\n",
      "Epoch 43/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - accuracy: 0.9125 - loss: 0.2404\n",
      "Epoch 44/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step - accuracy: 0.9167 - loss: 0.2333\n",
      "Epoch 45/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.9099 - loss: 0.2420\n",
      "Epoch 46/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - accuracy: 0.9132 - loss: 0.2415\n",
      "Epoch 47/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.9086 - loss: 0.2451\n",
      "Epoch 48/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - accuracy: 0.9141 - loss: 0.2365\n",
      "Epoch 49/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.9141 - loss: 0.2428\n",
      "Epoch 50/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483us/step - accuracy: 0.9121 - loss: 0.2372\n",
      "Epoch 51/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.9125 - loss: 0.2350\n",
      "Epoch 52/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.9201 - loss: 0.2293\n",
      "Epoch 53/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.9172 - loss: 0.2356\n",
      "Epoch 54/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2323\n",
      "Epoch 55/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2278\n",
      "Epoch 56/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.9169 - loss: 0.2296\n",
      "Epoch 57/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.9198 - loss: 0.2304\n",
      "Epoch 58/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.9169 - loss: 0.2336\n",
      "Epoch 59/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - accuracy: 0.9136 - loss: 0.2367\n",
      "Epoch 60/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.9152 - loss: 0.2303\n",
      "Epoch 61/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.9176 - loss: 0.2274\n",
      "Epoch 62/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - accuracy: 0.9184 - loss: 0.2281\n",
      "Epoch 63/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.9180 - loss: 0.2327\n",
      "Epoch 64/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.9165 - loss: 0.2254\n",
      "Epoch 65/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.9151 - loss: 0.2299\n",
      "Epoch 66/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.9150 - loss: 0.2298\n",
      "Epoch 67/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.9210 - loss: 0.2214\n",
      "Epoch 68/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.9204 - loss: 0.2226\n",
      "Epoch 69/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.9174 - loss: 0.2289\n",
      "Epoch 70/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.9150 - loss: 0.2390\n",
      "Epoch 71/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.9184 - loss: 0.2220\n",
      "Epoch 72/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.9167 - loss: 0.2348\n",
      "Epoch 73/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.9134 - loss: 0.2305\n",
      "Epoch 74/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.9187 - loss: 0.2286\n",
      "Epoch 75/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.9130 - loss: 0.2424\n",
      "Epoch 76/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.9178 - loss: 0.2198\n",
      "Epoch 77/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.9179 - loss: 0.2199\n",
      "Epoch 78/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.9212 - loss: 0.2179\n",
      "Epoch 79/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.9141 - loss: 0.2305\n",
      "Epoch 80/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.9219 - loss: 0.2197\n",
      "Epoch 81/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.9186 - loss: 0.2297\n",
      "Epoch 82/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.9183 - loss: 0.2178\n",
      "Epoch 83/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.9157 - loss: 0.2271\n",
      "Epoch 84/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.9156 - loss: 0.2252\n",
      "Epoch 85/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.9172 - loss: 0.2273\n",
      "Epoch 86/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.9151 - loss: 0.2307\n",
      "Epoch 87/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.9166 - loss: 0.2278\n",
      "Epoch 88/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.9191 - loss: 0.2184\n",
      "Epoch 89/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.9266 - loss: 0.2073\n",
      "Epoch 90/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2289\n",
      "Epoch 91/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.9190 - loss: 0.2263\n",
      "Epoch 92/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.9195 - loss: 0.2199\n",
      "Epoch 93/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.9145 - loss: 0.2270\n",
      "Epoch 94/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.9202 - loss: 0.2155\n",
      "Epoch 95/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.9148 - loss: 0.2256\n",
      "Epoch 96/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.9152 - loss: 0.2177\n",
      "Epoch 97/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.9198 - loss: 0.2211\n",
      "Epoch 98/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.9237 - loss: 0.2110\n",
      "Epoch 99/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9208 - loss: 0.2096\n",
      "Epoch 100/100\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9202 - loss: 0.2102\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fba37f9-cd63-42a7-851c-e4f6180e6b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n"
     ]
    }
   ],
   "source": [
    "yhat_test = classifier.predict(X_test)\n",
    "yhat_train = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e86991-3c8c-46d8-8236-b3eb7c2d414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[125,   0,   6,   0,   2,   2,   2],\n",
       "       [  0,  63,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 187,   0,   5,   1,   2],\n",
       "       [  0,   0,   0, 332,   0,   4,   6],\n",
       "       [  0,   0,   2,   2, 172,   0,   5],\n",
       "       [  1,   0,   0,   4,   0, 192,   3],\n",
       "       [  0,   0,   0,  45,   4,   8, 187]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1040,    0,   94,    1,    1,   20,   29],\n",
       "       [   0,  459,    0,    0,    0,    0,    0],\n",
       "       [  24,    0, 1359,    0,   31,    3,   18],\n",
       "       [   0,    0,    0, 3058,    1,   66,   79],\n",
       "       [   2,    0,   20,   18, 1648,    0,   59],\n",
       "       [   3,    0,    0,   21,    0, 1764,   39],\n",
       "       [   3,    0,    1,  360,   15,   62, 1951]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_test = confusion_matrix(np.argmax(y_test, axis = 1), np.argmax(yhat_test, axis = 1))\n",
    "print(\"Test Confusion Matrix\")\n",
    "display(confusion_matrix_test)\n",
    "confusion_matrix_train = confusion_matrix(np.argmax(y_train, axis = 1), np.argmax(yhat_train, axis = 1))\n",
    "print(\"Train Confusion Matrix\")\n",
    "display(confusion_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbb4685-73f2-40c2-b23a-4b0b29532544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x3002ebdd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm_disp_test = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_test, display_labels=y_test.columns)\n",
    "cm_disp_test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f79e977f-fecb-4340-a625-9f1fa6d0db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       137\n",
      "           1       1.00      1.00      1.00        63\n",
      "           2       0.96      0.96      0.96       195\n",
      "           3       0.87      0.97      0.92       342\n",
      "           4       0.94      0.95      0.95       181\n",
      "           5       0.93      0.96      0.94       200\n",
      "           6       0.91      0.77      0.83       244\n",
      "\n",
      "    accuracy                           0.92      1362\n",
      "   macro avg       0.94      0.93      0.94      1362\n",
      "weighted avg       0.93      0.92      0.92      1362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test, axis = 1),np.argmax(yhat_test, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db025543-c6aa-42d3-be92-7867140af446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29176642906592426"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_test-yhat_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eac87c9-05d2-4111-9820-ad7f626d9867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9236417033773862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(np.argmax(y_test, axis = 1),np.argmax(yhat_test, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f5188",
   "metadata": {
    "id": "083f5188"
   },
   "source": [
    "## Exercise 2 : k-fold Cross Validation (20 points)\n",
    "\n",
    "In order to avoid **using biased models**, use 10-fold cross validation to generalize the model from Ex1.2 on the given data set. You can choose a n_repeats value of 1-5\n",
    "\n",
    "__Requirements :__\n",
    "- Print the accuracy values during each iteration of the **cross validation** not the iterations per epoch or the epochs\n",
    "- Print the overall average accuracy per each n_fold value, look at the documentation for the scoring parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97e16034-db97-4baf-940e-d5e52b4ae044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Obtaining dependency information for scikeras from https://files.pythonhosted.org/packages/ea/09/1c02aa24daf7a003c06f629fbb69dc9ae1bda1b247d7b8981e550d752ac9/scikeras-0.13.0-py3-none-any.whl.metadata\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting keras>=3.2.0 (from scikeras)\n",
      "  Obtaining dependency information for keras>=3.2.0 from https://files.pythonhosted.org/packages/46/43/03fa53f027e78af4a6bee3564d05cb34d9f5b924dc69c85f8ef5cb950ff1/keras-3.4.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from scikeras) (1.4.2)\n",
      "Requirement already satisfied: absl-py in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->scikeras) (1.23.5)\n",
      "Requirement already satisfied: rich in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Collecting namex (from keras>=3.2.0->scikeras)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Collecting optree (from keras>=3.2.0->scikeras)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/2b/ce/4e2356b033c4822cce66249e58c5c5f37921cdb1b05acdaa27fcb31ea5fd/optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes (from keras>=3.2.0->scikeras)\n",
      "  Obtaining dependency information for ml-dtypes from https://files.pythonhosted.org/packages/42/6b/b2fa3e2386c2b7dde43f12b83c67f6e583039141dfbb58e5c8fd365a5a7d/ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->scikeras) (24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl (390 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.9/390.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl (283 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, keras, scikeras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0 requires jax>=0.3.15, which is not installed.\n",
      "tensorflow 2.12.0 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-3.4.1 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1 scikeras-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tu8rIov607s4",
   "metadata": {
    "id": "tu8rIov607s4"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27aab824-e92e-4689-bc5a-4c41121e1484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "2024-07-22 21:47:14.180848: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.223761: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.259881: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.260287: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.262702: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.265867: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.274177: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-22 21:47:14.281159: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  3.1min remaining:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  3.2min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "def buildmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(16,)))\n",
    "    model.add(Dense(12, activation = 'sigmoid'))\n",
    "    model.add(Dense(12, activation = 'sigmoid'))\n",
    "    model.add(Dense(12, activation = 'sigmoid'))\n",
    "    model.add(Dense(12, activation = 'sigmoid'))\n",
    "    model.add(Dense(7, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=SGD(learning_rate=0.3), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "estimator = KerasClassifier(model=buildmodel, epochs=100, batch_size=10, verbose=0)\n",
    "kfold = RepeatedKFold(n_splits = 10, n_repeats = 1)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold, n_jobs = -1, verbose=3)  # 1 cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40816b0c-3cd4-4983-abee-ff97b3a71d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91755102, 0.93469388, 0.89714286, 0.91265306, 0.91755102,\n",
       "       0.92163265, 0.91673469, 0.92244898, 0.92408163, 0.93055556])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b903a90-dc48-4066-9c33-7916139713a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9195045351473923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b571dcc-0cda-448b-9092-548eb143cfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.buildmodel()>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': 10,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 0,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 100,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef874c5",
   "metadata": {
    "id": "cef874c5"
   },
   "source": [
    "## Exercise 3 : Hyperparameter Tuning (25 points)\n",
    "\n",
    "Use either grid search or random search methodology to find the optimal number of nodes required in each hidden layer, as well as the optimal learning rate and the different activation functions or optimization approaches, [keras_tuner examples](https://keras.io/guides/keras_tuner/getting_started/) such that the accuracy of the model is maximum for the given data set.\n",
    "\n",
    "__Requirements :__\n",
    "- The set of optimal hyperparameters\n",
    "- The maximum accuracy achieved using this set of optimal hyperparameters\n",
    "\n",
    "__Note :__ Hyperparameter tuning takes a lot of time to execute. Make sure that you choose the appropriate number of each hyperparameter (preferably 3 of each), and that you allocate enough time to execute your code. Make sure to tune at least three parameters with three options each at a minimum, but feel free to experiment with more, just recognize that it will grow exponentially in running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5572c87d",
   "metadata": {
    "id": "5572c87d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in /Users/froguro/anaconda3/lib/python3.11/site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras_tuner) (2.12.0)\n",
      "Requirement already satisfied: packaging in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras_tuner) (24.1)\n",
      "Requirement already satisfied: requests in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras_tuner) (2.32.2)\n",
      "Requirement already satisfied: kt-legacy in /Users/froguro/anaconda3/lib/python3.11/site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from requests->keras_tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from requests->keras_tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from requests->keras_tuner) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/froguro/anaconda3/lib/python3.11/site-packages (from requests->keras_tuner) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "232d49bb-b402-4e00-a7ad-150a047d3f1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/froguro/anaconda3/lib/python3.11/site-packages/grpc/_cython/cygrpc.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN4absl12lts_2021110219str_format_internal13FormatArgImpl8DispatchINS0_11string_viewEEEbNS2_4DataENS1_24FormatConversionSpecImplEPv\n  Referenced from: <9F658FF6-372A-356B-B085-52035629693E> /Users/froguro/anaconda3/lib/libgpr.26.0.0.dylib\n  Expected in:     <A88D105C-34CE-3E35-A26D-BD14485CB27F> /Users/froguro/anaconda3/lib/libabsl_str_format_internal.2111.0.0.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/protos/__init__.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v4 \u001b[38;5;28;01mas\u001b[39;00m protos\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/protos/v4/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_pb2_grpc\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_pb2\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/protos/v4/keras_tuner_pb2_grpc.py:17\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Client and server classes corresponding to protobuf-defined services.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/grpc/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compression\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cygrpc \u001b[38;5;28;01mas\u001b[39;00m _cygrpc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/grpc/_compression.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The gRPC authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cygrpc\n\u001b[1;32m     17\u001b[0m NoCompression \u001b[38;5;241m=\u001b[39m cygrpc\u001b[38;5;241m.\u001b[39mCompressionAlgorithm\u001b[38;5;241m.\u001b[39mnone\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/froguro/anaconda3/lib/python3.11/site-packages/grpc/_cython/cygrpc.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN4absl12lts_2021110219str_format_internal13FormatArgImpl8DispatchINS0_11string_viewEEEbNS2_4DataENS1_24FormatConversionSpecImplEPv\n  Referenced from: <9F658FF6-372A-356B-B085-52035629693E> /Users/froguro/anaconda3/lib/libgpr.26.0.0.dylib\n  Expected in:     <A88D105C-34CE-3E35-A26D-BD14485CB27F> /Users/froguro/anaconda3/lib/libabsl_str_format_internal.2111.0.0.dylib",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m engine\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m oracles\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/engine/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_tuner\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hypermodel\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hyperparameters\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/engine/base_tuner/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_tuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTuner\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m config_module\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m oracles\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tuners\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_export\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/oracles/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianOptimizationOracle\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridsearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchOracle\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperband\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HyperbandOracle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/tuners/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianOptimization\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridsearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearch\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperband\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hyperband\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/tuners/bayesian.py:31\u001b[0m\n\u001b[1;32m     28\u001b[0m     scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_export\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hyperparameters \u001b[38;5;28;01mas\u001b[39;00m hp_module\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m oracle \u001b[38;5;28;01mas\u001b[39;00m oracle_module\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trial \u001b[38;5;28;01mas\u001b[39;00m trial_module\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/hyperparameters/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_export\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hp_types\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Boolean\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Choice\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/hyperparameters/hp_types/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp_types\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboolean_hp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Boolean\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp_types\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchoice_hp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Choice\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp_types\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixed_hp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fixed\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/hyperparameters/hp_types/boolean_hp.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m protos\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_export\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m conditions \u001b[38;5;28;01mas\u001b[39;00m conditions_mod\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/protos/__init__.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v4 \u001b[38;5;28;01mas\u001b[39;00m protos\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v3 \u001b[38;5;28;01mas\u001b[39;00m protos\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_proto\u001b[39m():\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mkeras_tuner_pb2\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/protos/v3/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_pb2_grpc\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tuner_pb2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service_pb2\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/protos/v3/keras_tuner_pb2_grpc.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The KerasTuner Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Client and server classes corresponding to protobuf-defined services.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/grpc/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compression\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cygrpc \u001b[38;5;28;01mas\u001b[39;00m _cygrpc\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_runtime_protos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m protos\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/grpc/_compression.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The gRPC authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cygrpc\n\u001b[1;32m     17\u001b[0m NoCompression \u001b[38;5;241m=\u001b[39m cygrpc\u001b[38;5;241m.\u001b[39mCompressionAlgorithm\u001b[38;5;241m.\u001b[39mnone\n\u001b[1;32m     18\u001b[0m Deflate \u001b[38;5;241m=\u001b[39m cygrpc\u001b[38;5;241m.\u001b[39mCompressionAlgorithm\u001b[38;5;241m.\u001b[39mdeflate\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/froguro/anaconda3/lib/python3.11/site-packages/grpc/_cython/cygrpc.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN4absl12lts_2021110219str_format_internal13FormatArgImpl8DispatchINS0_11string_viewEEEbNS2_4DataENS1_24FormatConversionSpecImplEPv\n  Referenced from: <9F658FF6-372A-356B-B085-52035629693E> /Users/froguro/anaconda3/lib/libgpr.26.0.0.dylib\n  Expected in:     <A88D105C-34CE-3E35-A26D-BD14485CB27F> /Users/froguro/anaconda3/lib/libabsl_str_format_internal.2111.0.0.dylib"
     ]
    }
   ],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nPfZ4mzk09EI",
   "metadata": {
    "id": "nPfZ4mzk09EI"
   },
   "source": [
    "## Exercise 4 - Collaborative Statement (5 points)\n",
    "\n",
    "It is mandatory to include a Statement of Collaboration in each submission, that follows the guidelines below.\n",
    "Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments in particular, I encourage students to organize (perhaps using Piazza) to discuss the\n",
    "task descriptions, requirements, possible bugs in the support code, and the relevant technical content before they\n",
    "start working on it. However, you should not discuss the specific solutions, and as a guiding principle, you are\n",
    "not allowed to take anything written or drawn away from these discussions (no photographs of the blackboard,\n",
    "written notes, referring to Piazza, etc.). Especially after you have started working on the assignment, try to restrict\n",
    "the discussion to Piazza as much as possible, so that there is no doubt as to the extent of your collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Cawhjqe09Q6",
   "metadata": {
    "id": "5Cawhjqe09Q6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
